# 数据库读写分离方案

## 1. 方案概述

### 1.1 目标
- **提升系统性能**：将读操作分散到从库，减轻主库压力
- **提高并发能力**：支持更多的并发读取操作
- **保证数据一致性**：确保写操作的强一致性，读操作的最终一致性
- **故障转移**：提供主从切换能力，提高系统可用性

### 1.2 当前架构分析
```
现有架构：
- Spring Boot + MyBatis
- 支持MySQL和PostgreSQL双数据库
- 多服务架构：common-service、order-service、market-service
- MyBatis XML配置 + DatabaseIdProvider
```

### 1.3 目标架构
```
读写分离架构：
Master数据库（主库）：处理所有写操作（INSERT、UPDATE、DELETE）
Slave数据库（从库）：处理所有读操作（SELECT）
```

## 2. 技术实现方案

### 2.1 方案选择对比

| 方案 | 优点 | 缺点 | 适用场景 |
|------|------|------|----------|
| **动态数据源切换** | 灵活、可控性强 | 开发复杂度高 | 复杂业务场景 |
| **MyBatis Plugin** | 自动化程度高 | 对MyBatis依赖强 | 纯MyBatis项目 |
| **Sharding-JDBC** | 功能全面、成熟 | 引入复杂性 | 大型项目 |
| **注解驱动** | 简单易用 | 灵活性有限 | 中小型项目 |

**推荐方案**：动态数据源切换 + 注解驱动（适合当前项目）

### 2.2 核心组件设计

#### **2.2.1 数据源枚举**
```java
public enum DataSourceType {
    MASTER,  // 主库（写）
    SLAVE    // 从库（读）
}
```

#### **2.2.2 数据源上下文**
```java
/**
 * 数据源上下文持有器
 * 使用ThreadLocal确保线程安全
 */
public class DataSourceContextHolder {
    private static final ThreadLocal<DataSourceType> CONTEXT_HOLDER = new ThreadLocal<>();
    
    /**
     * 设置数据源类型
     */
    public static void setDataSourceType(DataSourceType dataSourceType) {
        CONTEXT_HOLDER.set(dataSourceType);
    }
    
    /**
     * 获取数据源类型
     */
    public static DataSourceType getDataSourceType() {
        return CONTEXT_HOLDER.get();
    }
    
    /**
     * 清除数据源类型
     */
    public static void clearDataSourceType() {
        CONTEXT_HOLDER.remove();
    }
    
    /**
     * 重置为主库
     */
    public static void useMaster() {
        setDataSourceType(DataSourceType.MASTER);
    }
    
    /**
     * 切换到从库
     */
    public static void useSlave() {
        setDataSourceType(DataSourceType.SLAVE);
    }
}
```

#### **2.2.3 动态数据源**
```java
/**
 * 动态数据源路由
 * 根据上下文动态选择主库或从库
 */
public class DynamicDataSource extends AbstractRoutingDataSource {
    
    @Override
    protected Object determineCurrentLookupKey() {
        DataSourceType dataSourceType = DataSourceContextHolder.getDataSourceType();
        
        // 如果没有设置，默认使用主库
        if (dataSourceType == null) {
            return DataSourceType.MASTER;
        }
        
        return dataSourceType;
    }
    
    /**
     * 主库是否可用检查
     */
    private boolean isMasterAvailable() {
        // 实现主库健康检查逻辑
        return true;
    }
    
    /**
     * 从库是否可用检查
     */
    private boolean isSlaveAvailable() {
        // 实现从库健康检查逻辑
        return true;
    }
}
```

#### **2.2.4 读写分离注解**
```java
/**
 * 读操作注解
 * 标记方法使用从库
 */
@Target({ElementType.METHOD, ElementType.TYPE})
@Retention(RetentionPolicy.RUNTIME)
@Documented
public @interface ReadOnly {
    /**
     * 是否强制使用主库（用于读取刚写入的数据）
     */
    boolean forceMaster() default false;
}

/**
 * 写操作注解
 * 标记方法使用主库
 */
@Target({ElementType.METHOD, ElementType.TYPE})
@Retention(RetentionPolicy.RUNTIME)
@Documented
public @interface WriteOnly {
}
```

#### **2.2.5 AOP切面**
```java
/**
 * 数据源切换切面
 * 自动根据方法注解切换数据源
 */
@Aspect
@Component
@Slf4j
@Order(1) // 确保在事务切面之前执行
public class DataSourceAspect {
    
    @Pointcut("@annotation(com.binaryoption.common.annotation.ReadOnly)")
    public void readOnlyPointcut() {}
    
    @Pointcut("@annotation(com.binaryoption.common.annotation.WriteOnly)")
    public void writeOnlyPointcut() {}
    
    @Around("readOnlyPointcut()")
    public Object aroundReadOnly(ProceedingJoinPoint joinPoint) throws Throwable {
        MethodSignature signature = (MethodSignature) joinPoint.getSignature();
        ReadOnly readOnly = signature.getMethod().getAnnotation(ReadOnly.class);
        
        // 检查是否强制使用主库
        if (readOnly.forceMaster()) {
            log.debug("Force using MASTER datasource for method: {}", signature.getName());
            DataSourceContextHolder.useMaster();
        } else {
            log.debug("Using SLAVE datasource for method: {}", signature.getName());
            DataSourceContextHolder.useSlave();
        }
        
        try {
            return joinPoint.proceed();
        } finally {
            DataSourceContextHolder.clearDataSourceType();
        }
    }
    
    @Around("writeOnlyPointcut()")
    public Object aroundWriteOnly(ProceedingJoinPoint joinPoint) throws Throwable {
        MethodSignature signature = (MethodSignature) joinPoint.getSignature();
        log.debug("Using MASTER datasource for method: {}", signature.getName());
        
        DataSourceContextHolder.useMaster();
        
        try {
            return joinPoint.proceed();
        } finally {
            DataSourceContextHolder.clearDataSourceType();
        }
    }
    
    /**
     * 自动检测方法类型（如果没有注解）
     */
    @Around("execution(* com.binaryoption..service..*(..))")
    public Object aroundService(ProceedingJoinPoint joinPoint) throws Throwable {
        MethodSignature signature = (MethodSignature) joinPoint.getSignature();
        String methodName = signature.getName();
        
        // 如果已经有注解，跳过自动检测
        if (signature.getMethod().isAnnotationPresent(ReadOnly.class) || 
            signature.getMethod().isAnnotationPresent(WriteOnly.class)) {
            return joinPoint.proceed();
        }
        
        // 根据方法名自动判断读写类型
        if (isReadMethod(methodName)) {
            log.debug("Auto-detected READ operation for method: {}", methodName);
            DataSourceContextHolder.useSlave();
        } else {
            log.debug("Auto-detected WRITE operation for method: {}", methodName);
            DataSourceContextHolder.useMaster();
        }
        
        try {
            return joinPoint.proceed();
        } finally {
            DataSourceContextHolder.clearDataSourceType();
        }
    }
    
    /**
     * 判断是否为读方法
     */
    private boolean isReadMethod(String methodName) {
        return methodName.startsWith("get") || 
               methodName.startsWith("find") || 
               methodName.startsWith("select") || 
               methodName.startsWith("query") || 
               methodName.startsWith("count") || 
               methodName.startsWith("exist");
    }
}
```

## 3. 配置实现

### 3.1 数据源配置

#### **3.1.1 application.yml**
```yaml
spring:
  # 主数据源配置
  datasource:
    master:
      jdbc-url: jdbc:mysql://localhost:3306/binary_option_master?useUnicode=true&characterEncoding=utf8&serverTimezone=Asia/Shanghai
      username: root
      password: root
      driver-class-name: com.mysql.cj.jdbc.Driver
      hikari:
        minimum-idle: 10
        maximum-pool-size: 20
        idle-timeout: 600000
        max-lifetime: 1800000
        connection-timeout: 30000
        
    # 从数据源配置
    slave:
      jdbc-url: jdbc:mysql://localhost:3307/binary_option_slave?useUnicode=true&characterEncoding=utf8&serverTimezone=Asia/Shanghai
      username: root
      password: root
      driver-class-name: com.mysql.cj.jdbc.Driver
      hikari:
        minimum-idle: 5
        maximum-pool-size: 15
        idle-timeout: 600000
        max-lifetime: 1800000
        connection-timeout: 30000

# PostgreSQL配置（可选）
---
spring:
  profiles: postgresql
  datasource:
    master:
      jdbc-url: jdbc:postgresql://localhost:5432/binary_option_master
      username: postgres
      password: root
      driver-class-name: org.postgresql.Driver
      
    slave:
      jdbc-url: jdbc:postgresql://localhost:5433/binary_option_slave
      username: postgres
      password: root
      driver-class-name: org.postgresql.Driver

# 读写分离配置
datasource:
  read-write-separation:
    enabled: true
    # 从库连接失败时是否自动切换到主库
    fallback-to-master: true
    # 健康检查间隔（秒）
    health-check-interval: 30
```

#### **3.1.2 数据源配置类**
```java
@Configuration
@EnableAutoConfiguration(exclude = {DataSourceAutoConfiguration.class})
@EnableTransactionManagement
@EnableAspectJAutoProxy
public class DataSourceConfig {
    
    @Bean
    @ConfigurationProperties("spring.datasource.master")
    public DataSource masterDataSource() {
        return DataSourceBuilder.create()
            .type(HikariDataSource.class)
            .build();
    }
    
    @Bean
    @ConfigurationProperties("spring.datasource.slave")
    public DataSource slaveDataSource() {
        return DataSourceBuilder.create()
            .type(HikariDataSource.class)
            .build();
    }
    
    @Bean
    @Primary
    public DynamicDataSource dynamicDataSource() {
        DynamicDataSource dynamicDataSource = new DynamicDataSource();
        
        Map<Object, Object> dataSourceMap = new HashMap<>();
        dataSourceMap.put(DataSourceType.MASTER, masterDataSource());
        dataSourceMap.put(DataSourceType.SLAVE, slaveDataSource());
        
        // 设置数据源映射
        dynamicDataSource.setTargetDataSources(dataSourceMap);
        // 设置默认数据源为主库
        dynamicDataSource.setDefaultTargetDataSource(masterDataSource());
        
        return dynamicDataSource;
    }
    
    @Bean
    public SqlSessionFactory sqlSessionFactory() throws Exception {
        SqlSessionFactoryBean factoryBean = new SqlSessionFactoryBean();
        factoryBean.setDataSource(dynamicDataSource());
        
        // MyBatis配置
        org.apache.ibatis.session.Configuration configuration = new org.apache.ibatis.session.Configuration();
        configuration.setMapUnderscoreToCamelCase(true);
        configuration.setCacheEnabled(true);
        configuration.setLazyLoadingEnabled(true);
        
        // 数据库ID提供器（支持MySQL/PostgreSQL）
        DatabaseIdProvider databaseIdProvider = new VendorDatabaseIdProvider();
        Properties properties = new Properties();
        properties.setProperty("MySQL", "mysql");
        properties.setProperty("PostgreSQL", "postgresql");
        databaseIdProvider.setProperties(properties);
        factoryBean.setDatabaseIdProvider(databaseIdProvider);
        
        factoryBean.setConfiguration(configuration);
        factoryBean.setMapperLocations(new PathMatchingResourcePatternResolver()
            .getResources("classpath:mapper/*.xml"));
        
        return factoryBean.getObject();
    }
    
    @Bean
    @Primary
    public DataSourceTransactionManager transactionManager() {
        return new DataSourceTransactionManager(dynamicDataSource());
    }
}
```

### 3.2 MyBatis配置优化

#### **3.2.1 Mapper接口优化**
```java
@Mapper
public interface OrderMapper {
    
    // 写操作 - 自动使用主库
    @WriteOnly
    int insert(Order order);
    
    @WriteOnly
    int update(Order order);
    
    @WriteOnly
    int delete(@Param("id") Long id);
    
    // 读操作 - 自动使用从库
    @ReadOnly
    Order selectById(@Param("id") Long id);
    
    @ReadOnly
    List<Order> selectByUserId(@Param("userId") Long userId);
    
    // 需要强一致性的读操作 - 强制使用主库
    @ReadOnly(forceMaster = true)
    Order selectByIdForUpdate(@Param("id") Long id);
    
    @ReadOnly
    List<Order> selectByCondition(@Param("condition") OrderQueryCondition condition);
    
    @ReadOnly
    int count(@Param("condition") OrderQueryCondition condition);
}
```

#### **3.2.2 Service层应用**
```java
@Service
@Transactional(rollbackFor = Exception.class)
@Slf4j
public class OrderService {
    
    @Autowired
    private OrderMapper orderMapper;
    
    /**
     * 创建订单 - 写操作，自动使用主库
     */
    @WriteOnly
    public Result<OrderDTO> createOrder(CreateOrderDTO request) {
        // 写操作逻辑
        Order order = convertToOrder(request);
        orderMapper.insert(order);
        
        return Result.success(convertToDTO(order));
    }
    
    /**
     * 查询订单 - 读操作，自动使用从库
     */
    @ReadOnly
    @Transactional(readOnly = true)
    public Result<OrderDTO> getOrder(Long orderId) {
        Order order = orderMapper.selectById(orderId);
        return Result.success(convertToDTO(order));
    }
    
    /**
     * 查询用户订单列表 - 读操作，使用从库
     */
    @ReadOnly
    @Transactional(readOnly = true)
    public Result<List<OrderDTO>> getUserOrders(Long userId) {
        List<Order> orders = orderMapper.selectByUserId(userId);
        return Result.success(convertToDTO(orders));
    }
    
    /**
     * 更新订单状态 - 写操作后立即查询，需要强一致性
     */
    @WriteOnly
    public Result<OrderDTO> updateOrderStatus(Long orderId, String status) {
        // 更新操作使用主库
        Order order = orderMapper.selectById(orderId);
        order.setStatus(status);
        orderMapper.update(order);
        
        // 立即查询刚更新的数据，需要从主库读取
        order = orderMapper.selectByIdForUpdate(orderId);
        
        return Result.success(convertToDTO(order));
    }
}
```

## 4. 事务处理策略

### 4.1 事务与读写分离的协调

#### **4.1.1 事务传播处理**
```java
@Component
public class TransactionDataSourceAspect {
    
    @Around("@annotation(org.springframework.transaction.annotation.Transactional)")
    public Object aroundTransaction(ProceedingJoinPoint joinPoint) throws Throwable {
        MethodSignature signature = (MethodSignature) joinPoint.getSignature();
        Transactional transactional = signature.getMethod().getAnnotation(Transactional.class);
        
        // 如果是只读事务，强制使用从库
        if (transactional != null && transactional.readOnly()) {
            DataSourceContextHolder.useSlave();
        } else {
            // 写事务或未指定，使用主库
            DataSourceContextHolder.useMaster();
        }
        
        try {
            return joinPoint.proceed();
        } finally {
            DataSourceContextHolder.clearDataSourceType();
        }
    }
}
```

#### **4.1.2 分布式事务考虑**
```java
@Service
public class OrderTransactionService {
    
    /**
     * 复杂业务事务 - 需要保证强一致性
     */
    @Transactional(rollbackFor = Exception.class)
    @WriteOnly
    public Result<OrderDTO> createOrderWithAccount(CreateOrderDTO request) {
        // 整个事务使用主库，保证一致性
        
        // 1. 检查账户余额（使用主库）
        Account account = accountMapper.selectByUserIdForUpdate(request.getUserId());
        
        // 2. 冻结资金
        accountService.freezeBalance(account.getId(), request.getAmount());
        
        // 3. 创建订单
        Order order = createOrder(request);
        
        // 4. 记录交易流水
        transactionService.recordTransaction(order);
        
        return Result.success(convertToDTO(order));
    }
}
```

## 5. 主从复制配置

### 5.1 MySQL主从配置

#### **5.1.1 主库配置（my.cnf）**
```ini
[mysqld]
# 服务器ID，主库设置为1
server-id = 1

# 启用二进制日志
log-bin = mysql-bin
binlog-format = ROW

# 要复制的数据库
binlog-do-db = binary_option

# 不复制的数据库
binlog-ignore-db = mysql
binlog-ignore-db = information_schema
binlog-ignore-db = performance_schema

# 二进制日志保留天数
expire_logs_days = 7

# 从库连接的用户权限
# CREATE USER 'repl'@'%' IDENTIFIED BY 'replica_password';
# GRANT REPLICATION SLAVE ON *.* TO 'repl'@'%';
```

#### **5.1.2 从库配置（my.cnf）**
```ini
[mysqld]
# 服务器ID，从库设置为2
server-id = 2

# 只读模式
read-only = 1

# 中继日志
relay-log = mysql-relay-bin

# 复制过滤
replicate-do-db = binary_option
replicate-ignore-db = mysql
replicate-ignore-db = information_schema
replicate-ignore-db = performance_schema

# 启动复制命令：
# CHANGE MASTER TO
#   MASTER_HOST='master_host',
#   MASTER_USER='repl',
#   MASTER_PASSWORD='replica_password',
#   MASTER_LOG_FILE='mysql-bin.000001',
#   MASTER_LOG_POS=154;
# START SLAVE;
```

### 5.2 PostgreSQL主从配置

#### **5.2.1 主库配置（postgresql.conf）**
```ini
# WAL设置
wal_level = replica
max_wal_senders = 3
wal_keep_segments = 64

# 归档设置
archive_mode = on
archive_command = 'cp %p /var/lib/postgresql/archive/%f'
```

#### **5.2.2 从库配置（recovery.conf）**
```ini
standby_mode = 'on'
primary_conninfo = 'host=master_host port=5432 user=replicator password=replica_password'
trigger_file = '/tmp/postgresql.trigger'
```

## 6. 故障转移和监控

### 6.1 健康检查机制

#### **6.1.1 数据源健康检查**
```java
@Component
@Slf4j
public class DataSourceHealthChecker {
    
    @Autowired
    private DataSource masterDataSource;
    
    @Autowired
    private DataSource slaveDataSource;
    
    private volatile boolean masterHealthy = true;
    private volatile boolean slaveHealthy = true;
    
    @Scheduled(fixedDelay = 30000) // 每30秒检查一次
    public void checkDataSourceHealth() {
        checkMasterHealth();
        checkSlaveHealth();
    }
    
    private void checkMasterHealth() {
        try (Connection connection = masterDataSource.getConnection()) {
            PreparedStatement statement = connection.prepareStatement("SELECT 1");
            ResultSet resultSet = statement.executeQuery();
            boolean previousStatus = masterHealthy;
            masterHealthy = resultSet.next();
            
            if (previousStatus != masterHealthy) {
                log.warn("Master database health changed: {}", masterHealthy ? "HEALTHY" : "UNHEALTHY");
            }
        } catch (Exception e) {
            masterHealthy = false;
            log.error("Master database health check failed", e);
        }
    }
    
    private void checkSlaveHealth() {
        try (Connection connection = slaveDataSource.getConnection()) {
            PreparedStatement statement = connection.prepareStatement("SELECT 1");
            ResultSet resultSet = statement.executeQuery();
            boolean previousStatus = slaveHealthy;
            slaveHealthy = resultSet.next();
            
            if (previousStatus != slaveHealthy) {
                log.warn("Slave database health changed: {}", slaveHealthy ? "HEALTHY" : "UNHEALTHY");
            }
        } catch (Exception e) {
            slaveHealthy = false;
            log.error("Slave database health check failed", e);
        }
    }
    
    public boolean isMasterHealthy() {
        return masterHealthy;
    }
    
    public boolean isSlaveHealthy() {
        return slaveHealthy;
    }
}
```

#### **6.1.2 故障转移逻辑**
```java
public class EnhancedDynamicDataSource extends DynamicDataSource {
    
    @Autowired
    private DataSourceHealthChecker healthChecker;
    
    @Override
    protected Object determineCurrentLookupKey() {
        DataSourceType dataSourceType = DataSourceContextHolder.getDataSourceType();
        
        // 如果没有设置类型，默认使用主库
        if (dataSourceType == null) {
            return DataSourceType.MASTER;
        }
        
        // 如果请求从库但从库不健康，自动切换到主库
        if (dataSourceType == DataSourceType.SLAVE && !healthChecker.isSlaveHealthy()) {
            log.warn("Slave database is unhealthy, fallback to master");
            return DataSourceType.MASTER;
        }
        
        // 如果请求主库但主库不健康，这是严重问题
        if (dataSourceType == DataSourceType.MASTER && !healthChecker.isMasterHealthy()) {
            log.error("Master database is unhealthy! System may fail!");
            // 这里可以触发告警
        }
        
        return dataSourceType;
    }
}
```

### 6.2 监控指标

#### **6.2.1 数据源监控**
```java
@Component
public class DataSourceMetrics {
    
    private final MeterRegistry meterRegistry;
    private final Timer masterQueryTimer;
    private final Timer slaveQueryTimer;
    private final Counter masterConnectionCounter;
    private final Counter slaveConnectionCounter;
    
    public DataSourceMetrics(MeterRegistry meterRegistry) {
        this.meterRegistry = meterRegistry;
        this.masterQueryTimer = Timer.builder("datasource.query.time")
            .tag("datasource", "master")
            .register(meterRegistry);
        this.slaveQueryTimer = Timer.builder("datasource.query.time")
            .tag("datasource", "slave")
            .register(meterRegistry);
        this.masterConnectionCounter = Counter.builder("datasource.connections")
            .tag("datasource", "master")
            .register(meterRegistry);
        this.slaveConnectionCounter = Counter.builder("datasource.connections")
            .tag("datasource", "slave")
            .register(meterRegistry);
    }
    
    public Timer.Sample startTimer(DataSourceType type) {
        return type == DataSourceType.MASTER ? 
            Timer.start(meterRegistry) : Timer.start(meterRegistry);
    }
    
    public void recordQuery(DataSourceType type, Timer.Sample sample) {
        if (type == DataSourceType.MASTER) {
            sample.stop(masterQueryTimer);
            masterConnectionCounter.increment();
        } else {
            sample.stop(slaveQueryTimer);
            slaveConnectionCounter.increment();
        }
    }
}
```

## 7. 实施步骤

### 7.1 第一阶段：基础架构搭建（1-2天）

#### **步骤1：创建核心组件**
```bash
# 创建读写分离核心类
mkdir -p src/main/java/com/binaryoption/common/datasource
# - DataSourceType.java
# - DataSourceContextHolder.java
# - DynamicDataSource.java

mkdir -p src/main/java/com/binaryoption/common/annotation
# - ReadOnly.java
# - WriteOnly.java

mkdir -p src/main/java/com/binaryoption/common/aspect
# - DataSourceAspect.java
```

#### **步骤2：修改配置**
```bash
# 更新配置文件
# - application.yml
# - DataSourceConfig.java
```

#### **步骤3：测试验证**
```java
// 创建测试类验证数据源切换
@SpringBootTest
class DataSourceSwitchTest {
    
    @Test
    void testMasterDataSource() {
        // 验证写操作使用主库
    }
    
    @Test
    void testSlaveDataSource() {
        // 验证读操作使用从库
    }
}
```

### 7.2 第二阶段：业务代码改造（3-5天）

#### **步骤1：Service层添加注解**
```java
// 为所有Service方法添加@ReadOnly或@WriteOnly注解
// 重点关注：
// - OrderService
// - AccountService  
// - UserService
```

#### **步骤2：Mapper接口优化**
```java
// 为所有Mapper方法添加适当的注解
// 特别注意需要强一致性的查询操作
```

#### **步骤3：事务处理调整**
```java
// 调整事务注解，确保读写分离与事务的协调
```

### 7.3 第三阶段：数据库主从配置（1-2天）

#### **步骤1：配置主从复制**
```bash
# MySQL主从配置
# PostgreSQL流复制配置
```

#### **步骤2：数据同步验证**
```sql
-- 验证主从同步状态
SHOW SLAVE STATUS\G  -- MySQL
SELECT * FROM pg_stat_replication;  -- PostgreSQL
```

### 7.4 第四阶段：监控和优化（2-3天）

#### **步骤1：添加监控**
```java
// 健康检查
// 性能监控
// 告警机制
```

#### **步骤2：压力测试**
```bash
# 使用现有测试脚本进行压力测试
./test-scripts/simple-flow-test-oauth.sh
# 验证读写分离效果
```

## 8. 注意事项和最佳实践

### 8.1 数据一致性问题

#### **8.1.1 主从延迟**
```java
/**
 * 对于需要立即读取刚写入数据的场景，使用强制主库读取
 */
@Service
public class OrderService {
    
    @WriteOnly
    @Transactional
    public Result<OrderDTO> createOrder(CreateOrderDTO request) {
        // 创建订单
        Order order = new Order();
        orderMapper.insert(order);
        
        // 立即返回订单信息，从主库读取
        order = orderMapper.selectByIdForUpdate(order.getId()); // forceMaster=true
        
        return Result.success(convertToDTO(order));
    }
}
```

#### **8.1.2 读写事务隔离**
```java
// 避免在同一个事务中混合读写操作到不同数据源
@Transactional(readOnly = true)
@ReadOnly
public List<OrderDTO> getUserOrders(Long userId) {
    // 整个方法使用从库，保证事务一致性
    return orderMapper.selectByUserId(userId);
}
```

### 8.2 性能优化建议

#### **8.2.1 连接池优化**
```yaml
spring:
  datasource:
    master:
      hikari:
        minimum-idle: 10      # 主库保持较多连接
        maximum-pool-size: 30
    slave:
      hikari:
        minimum-idle: 5       # 从库连接可以少一些
        maximum-pool-size: 20
```

#### **8.2.2 缓存策略**
```java
// 对于频繁读取且变化不大的数据，使用缓存
@Service
public class SymbolService {
    
    @Cacheable(value = "symbols", key = "'active'")
    @ReadOnly
    public List<SymbolDTO> getActiveSymbols() {
        // 从从库读取，并缓存结果
        return symbolMapper.selectActive();
    }
}
```

### 8.3 故障处理

#### **8.3.1 从库故障**
- 自动切换到主库
- 记录告警日志
- 不影响业务正常运行

#### **8.3.2 主库故障**
- 立即告警
- 可考虑提升从库为主库（需要业务中断）
- 制定详细的故障恢复流程

### 8.4 代码规范

#### **8.4.1 注解使用规范**
```java
// 明确标记读写类型
@ReadOnly                    // ✅ 推荐
@ReadOnly(forceMaster=true)  // ✅ 需要强一致性时使用
@WriteOnly                   // ✅ 写操作

// 避免的用法
public void someMethod() {}  // ❌ 没有明确标记，依赖自动检测
```

#### **8.4.2 事务使用规范**
```java
@Transactional(readOnly = true)  // ✅ 明确只读事务
@ReadOnly
public List<Order> getOrders() {}

@Transactional               // ✅ 写事务
@WriteOnly  
public void updateOrder() {}
```

## 9. 监控和运维

### 9.1 关键监控指标

1. **主从延迟时间**
2. **数据源健康状态**  
3. **读写操作分布比例**
4. **连接池使用情况**
5. **查询响应时间**

### 9.2 日常运维

```bash
# 检查主从同步状态
./scripts/check-replication-status.sh

# 监控数据源健康
./scripts/monitor-datasource-health.sh

# 读写分离效果统计
./scripts/rw-separation-stats.sh
```

## 10. 预期效果

### 10.1 性能提升

- **读操作性能提升**：30-50%（分散到从库）
- **主库压力减轻**：50-70%（读操作分流）
- **并发能力提升**：2-3倍（读写分离）

### 10.2 可用性提升

- **故障容错**：从库故障不影响业务
- **负载均衡**：读写操作负载分散
- **扩展性**：可添加多个从库进一步分散读压力

这个方案为您的系统提供了完整的读写分离解决方案，既保证了数据一致性，又显著提升了系统性能和可用性。您觉得这个方案如何？需要我详细解释其中的某个部分吗？