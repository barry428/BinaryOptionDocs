# 数据库读写分离设计方案

## 1. 概述

数据库读写分离是一种常见的数据库架构优化方案，通过将读操作和写操作分发到不同的数据库实例，提高系统的并发处理能力和整体性能。

## 2. 架构设计

### 2.1 总体架构

```
                    应用层
                      |
              [动态数据源路由]
                   /     \
                  /       \
           [主库-写]    [从库-读]
         PostgreSQL    PostgreSQL
           (Master)     (Slave)
```

### 2.2 核心组件

1. **主数据库（Master）**：处理所有写操作（INSERT、UPDATE、DELETE）
2. **从数据库（Slave）**：处理只读查询（SELECT）
3. **动态数据源路由**：根据SQL类型自动路由到主库或从库
4. **事务管理器**：确保事务内的所有操作都在主库执行

## 3. Spring Boot实现方案

### 3.1 方案一：使用Spring AbstractRoutingDataSource

#### 3.1.1 创建数据源配置类

```java
package com.binaryoption.commonconfig.datasource;

import com.zaxxer.hikari.HikariConfig;
import com.zaxxer.hikari.HikariDataSource;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.Primary;

import javax.sql.DataSource;
import java.util.HashMap;
import java.util.Map;

@Configuration
public class DataSourceConfig {
    
    @Value("${spring.datasource.master.url}")
    private String masterUrl;
    
    @Value("${spring.datasource.master.username}")
    private String masterUsername;
    
    @Value("${spring.datasource.master.password}")
    private String masterPassword;
    
    @Value("${spring.datasource.slave.url}")
    private String slaveUrl;
    
    @Value("${spring.datasource.slave.username}")
    private String slaveUsername;
    
    @Value("${spring.datasource.slave.password}")
    private String slavePassword;
    
    @Bean
    public DataSource masterDataSource() {
        HikariConfig config = new HikariConfig();
        config.setJdbcUrl(masterUrl);
        config.setUsername(masterUsername);
        config.setPassword(masterPassword);
        config.setDriverClassName("org.postgresql.Driver");
        config.setMaximumPoolSize(20);
        config.setMinimumIdle(5);
        config.setConnectionTimeout(30000);
        config.setIdleTimeout(600000);
        config.setMaxLifetime(1800000);
        config.setPoolName("MasterHikariPool");
        return new HikariDataSource(config);
    }
    
    @Bean
    public DataSource slaveDataSource() {
        HikariConfig config = new HikariConfig();
        config.setJdbcUrl(slaveUrl);
        config.setUsername(slaveUsername);
        config.setPassword(slavePassword);
        config.setDriverClassName("org.postgresql.Driver");
        config.setMaximumPoolSize(30); // 从库可以有更多连接
        config.setMinimumIdle(10);
        config.setConnectionTimeout(30000);
        config.setIdleTimeout(600000);
        config.setMaxLifetime(1800000);
        config.setPoolName("SlaveHikariPool");
        return new HikariDataSource(config);
    }
    
    @Bean
    @Primary
    public DataSource dataSource() {
        DynamicDataSource dynamicDataSource = new DynamicDataSource();
        
        // 设置数据源映射
        Map<Object, Object> targetDataSources = new HashMap<>();
        targetDataSources.put(DataSourceType.MASTER, masterDataSource());
        targetDataSources.put(DataSourceType.SLAVE, slaveDataSource());
        dynamicDataSource.setTargetDataSources(targetDataSources);
        
        // 设置默认数据源为主库
        dynamicDataSource.setDefaultTargetDataSource(masterDataSource());
        
        return dynamicDataSource;
    }
}
```

#### 3.1.2 创建动态数据源路由类

```java
package com.binaryoption.commonconfig.datasource;

import org.springframework.jdbc.datasource.lookup.AbstractRoutingDataSource;

public class DynamicDataSource extends AbstractRoutingDataSource {
    
    private static final ThreadLocal<DataSourceType> contextHolder = new ThreadLocal<>();
    
    @Override
    protected Object determineCurrentLookupKey() {
        return getDataSourceType();
    }
    
    public static void setDataSourceType(DataSourceType dataSourceType) {
        contextHolder.set(dataSourceType);
    }
    
    public static DataSourceType getDataSourceType() {
        return contextHolder.get() != null ? contextHolder.get() : DataSourceType.MASTER;
    }
    
    public static void clearDataSourceType() {
        contextHolder.remove();
    }
}
```

#### 3.1.3 定义数据源类型枚举

```java
package com.binaryoption.commonconfig.datasource;

public enum DataSourceType {
    MASTER,  // 主库
    SLAVE    // 从库
}
```

#### 3.1.4 创建读写分离注解

```java
package com.binaryoption.commonconfig.annotation;

import java.lang.annotation.*;

@Target({ElementType.METHOD, ElementType.TYPE})
@Retention(RetentionPolicy.RUNTIME)
@Documented
public @interface ReadOnly {
    // 标记只读方法，使用从库
}

@Target({ElementType.METHOD, ElementType.TYPE})
@Retention(RetentionPolicy.RUNTIME)
@Documented
public @interface Master {
    // 强制使用主库
}
```

#### 3.1.5 创建AOP切面实现自动路由

```java
package com.binaryoption.commonconfig.aspect;

import com.binaryoption.commonconfig.annotation.Master;
import com.binaryoption.commonconfig.annotation.ReadOnly;
import com.binaryoption.commonconfig.datasource.DataSourceType;
import com.binaryoption.commonconfig.datasource.DynamicDataSource;
import lombok.extern.slf4j.Slf4j;
import org.aspectj.lang.ProceedingJoinPoint;
import org.aspectj.lang.annotation.Around;
import org.aspectj.lang.annotation.Aspect;
import org.aspectj.lang.reflect.MethodSignature;
import org.springframework.core.annotation.Order;
import org.springframework.stereotype.Component;
import org.springframework.transaction.annotation.Transactional;

import java.lang.reflect.Method;

@Slf4j
@Aspect
@Order(-1) // 保证在@Transactional之前执行
@Component
public class DataSourceAspect {
    
    @Around("@annotation(com.binaryoption.commonconfig.annotation.ReadOnly) || " +
            "@annotation(com.binaryoption.commonconfig.annotation.Master)")
    public Object around(ProceedingJoinPoint point) throws Throwable {
        MethodSignature signature = (MethodSignature) point.getSignature();
        Method method = signature.getMethod();
        
        DataSourceType dataSourceType = DataSourceType.MASTER;
        
        // 检查是否在事务中，事务中强制使用主库
        if (method.isAnnotationPresent(Transactional.class)) {
            dataSourceType = DataSourceType.MASTER;
        }
        // 检查@Master注解
        else if (method.isAnnotationPresent(Master.class)) {
            dataSourceType = DataSourceType.MASTER;
        }
        // 检查@ReadOnly注解
        else if (method.isAnnotationPresent(ReadOnly.class)) {
            dataSourceType = DataSourceType.SLAVE;
        }
        // 根据方法名自动判断
        else {
            String methodName = method.getName();
            if (isReadMethod(methodName)) {
                dataSourceType = DataSourceType.SLAVE;
            }
        }
        
        log.debug("使用数据源: {} for method: {}", dataSourceType, method.getName());
        DynamicDataSource.setDataSourceType(dataSourceType);
        
        try {
            return point.proceed();
        } finally {
            DynamicDataSource.clearDataSourceType();
        }
    }
    
    /**
     * 判断是否是读方法
     */
    private boolean isReadMethod(String methodName) {
        return methodName.startsWith("select") || 
               methodName.startsWith("get") || 
               methodName.startsWith("query") || 
               methodName.startsWith("find") ||
               methodName.startsWith("list") ||
               methodName.startsWith("count") ||
               methodName.startsWith("exist");
    }
}
```

### 3.2 方案二：使用ShardingSphere-JDBC（推荐）

#### 3.2.1 添加依赖

```xml
<dependency>
    <groupId>org.apache.shardingsphere</groupId>
    <artifactId>shardingsphere-jdbc-core</artifactId>
    <version>5.4.0</version>
</dependency>
```

#### 3.2.2 配置文件（application.yml）

```yaml
spring:
  shardingsphere:
    mode:
      type: Standalone
    
    datasource:
      names: master,slave0,slave1
      
      master:
        type: com.zaxxer.hikari.HikariDataSource
        driver-class-name: org.postgresql.Driver
        jdbc-url: jdbc:postgresql://master-db:5432/binary_option
        username: postgres
        password: password
        hikari:
          maximum-pool-size: 20
          minimum-idle: 5
      
      slave0:
        type: com.zaxxer.hikari.HikariDataSource
        driver-class-name: org.postgresql.Driver
        jdbc-url: jdbc:postgresql://slave1-db:5432/binary_option
        username: postgres
        password: password
        hikari:
          maximum-pool-size: 30
          minimum-idle: 10
      
      slave1:
        type: com.zaxxer.hikari.HikariDataSource
        driver-class-name: org.postgresql.Driver
        jdbc-url: jdbc:postgresql://slave2-db:5432/binary_option
        username: postgres
        password: password
        hikari:
          maximum-pool-size: 30
          minimum-idle: 10
    
    rules:
      readwrite-splitting:
        data-sources:
          readwrite_ds:
            static-strategy:
              write-data-source-name: master
              read-data-source-names:
                - slave0
                - slave1
            load-balancer-name: round_robin
        
        load-balancers:
          round_robin:
            type: ROUND_ROBIN
            props:
              # 轮询策略配置
    
    props:
      sql-show: true
      sql-simple: true
```

## 4. MyBatis集成

### 4.1 修改Mapper扫描配置

```java
@Configuration
@MapperScan(basePackages = "com.binaryoption.*.mapper")
public class MyBatisConfig {
    
    @Bean
    public SqlSessionFactory sqlSessionFactory(DataSource dataSource) throws Exception {
        SqlSessionFactoryBean sessionFactory = new SqlSessionFactoryBean();
        sessionFactory.setDataSource(dataSource);
        
        // 设置MyBatis配置
        org.apache.ibatis.session.Configuration configuration = new org.apache.ibatis.session.Configuration();
        configuration.setMapUnderscoreToCamelCase(true);
        configuration.setLogImpl(Slf4jImpl.class);
        sessionFactory.setConfiguration(configuration);
        
        // 设置Mapper XML位置
        PathMatchingResourcePatternResolver resolver = new PathMatchingResourcePatternResolver();
        sessionFactory.setMapperLocations(resolver.getResources("classpath:mapper/*.xml"));
        
        return sessionFactory.getObject();
    }
}
```

### 4.2 Service层使用示例

```java
@Service
@Slf4j
public class OrderService {
    
    @Autowired
    private OrderMapper orderMapper;
    
    /**
     * 查询订单 - 自动路由到从库
     */
    @ReadOnly
    public OrderDTO getOrderById(Long id) {
        Order order = orderMapper.findById(id);
        return orderConverter.toDTO(order);
    }
    
    /**
     * 创建订单 - 自动路由到主库
     */
    @Transactional
    public Result<OrderDTO> createOrder(OrderCreateRequestDTO request) {
        // 所有数据库操作都在主库执行
        Order order = new Order();
        // ... 设置订单属性
        orderMapper.insert(order);
        return Result.success(orderConverter.toDTO(order));
    }
    
    /**
     * 统计查询 - 使用从库
     */
    @ReadOnly
    public OrderStatsDTO getUserOrderStats(Long userId) {
        return orderMapper.getUserStatistics(userId);
    }
    
    /**
     * 强制使用主库查询（实时性要求高）
     */
    @Master
    public OrderDTO getLatestOrder(Long userId) {
        // 需要读取最新数据，避免主从延迟
        return orderMapper.findLatestByUserId(userId);
    }
}
```

## 5. 环境配置示例

### 5.1 开发环境 (application-dev.yml)

```yaml
spring:
  datasource:
    master:
      url: jdbc:postgresql://localhost:5433/binary_option
      username: postgres
      password: root
    slave:
      url: jdbc:postgresql://localhost:5433/binary_option  # 开发环境可以指向同一个库
      username: postgres
      password: root
    read-write-splitting:
      enabled: false  # 开发环境可以禁用读写分离
```

### 5.2 预发/生产环境 (application-staging.yml)

```yaml
spring:
  datasource:
    master:
      url: jdbc:postgresql://${DB_MASTER_HOST:master-db.internal}:5432/${DB_NAME:binary_option}
      username: ${DB_MASTER_USER:postgres}
      password: ${DB_MASTER_PASSWORD}
    slave:
      url: jdbc:postgresql://${DB_SLAVE_HOST:slave-db.internal}:5432/${DB_NAME:binary_option}
      username: ${DB_SLAVE_USER:postgres_read}
      password: ${DB_SLAVE_PASSWORD}
    read-write-splitting:
      enabled: true
      slave-count: 2  # 从库数量
      load-balance-algorithm: round_robin  # 负载均衡策略
```

## 6. 注意事项

### 6.1 主从延迟处理

1. **强制主库查询**：对于实时性要求高的查询，使用`@Master`注解
2. **延迟容忍**：对于报表、统计等场景，可以接受一定延迟
3. **读写一致性**：同一事务内的所有操作都在主库执行

### 6.2 事务处理

1. **事务边界**：确保`@Transactional`注解正确使用
2. **只读事务**：对于纯查询操作，使用`@Transactional(readOnly = true)`
3. **跨库事务**：避免跨多个数据源的分布式事务

### 6.3 监控和运维

1. **连接池监控**：分别监控主从库的连接池状态
2. **延迟监控**：监控主从复制延迟
3. **故障切换**：从库故障时自动切换到其他从库或主库

## 7. 性能优化建议

### 7.1 连接池优化

```yaml
hikari:
  # 主库配置（写操作较少）
  master:
    maximum-pool-size: 20
    minimum-idle: 5
    connection-timeout: 30000
  
  # 从库配置（读操作较多）
  slave:
    maximum-pool-size: 50
    minimum-idle: 20
    connection-timeout: 20000
```

### 7.2 缓存策略

1. **二级缓存**：配合Redis缓存减少数据库压力
2. **查询缓存**：MyBatis查询缓存配置
3. **应用缓存**：Spring Cache注解使用

## 8. 测试验证

### 8.1 单元测试

```java
@SpringBootTest
@ActiveProfiles("test")
public class ReadWriteSplitTest {
    
    @Autowired
    private OrderService orderService;
    
    @Test
    public void testReadFromSlave() {
        // 验证读操作路由到从库
        OrderDTO order = orderService.getOrderById(1L);
        assertNotNull(order);
    }
    
    @Test
    @Transactional
    public void testWriteToMaster() {
        // 验证写操作路由到主库
        OrderCreateRequestDTO request = new OrderCreateRequestDTO();
        Result<OrderDTO> result = orderService.createOrder(request);
        assertTrue(result.isSuccess());
    }
}
```

### 8.2 性能测试

1. **并发读测试**：验证从库分担读压力
2. **写入性能测试**：验证主库写入性能
3. **主从切换测试**：验证故障转移机制

## 9. 迁移计划

### 9.1 第一阶段：代码准备
1. 添加读写分离相关代码
2. 保持向后兼容
3. 充分测试

### 9.2 第二阶段：灰度发布
1. 选择部分服务启用读写分离
2. 监控性能指标
3. 逐步扩大范围

### 9.3 第三阶段：全量切换
1. 所有服务启用读写分离
2. 优化配置参数
3. 建立监控告警

---

**文档版本**: v1.0  
**创建日期**: 2025-10-14  
**更新日期**: 2025-10-14  
**维护人员**: Claude Code Assistant